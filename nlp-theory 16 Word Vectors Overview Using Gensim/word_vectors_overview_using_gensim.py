# -*- coding: utf-8 -*-
"""Word Vectors Overview Using Gensim.ipynb

Automatically generated by Colab.

### **NLP Tutorial: Word Vectors Overview Using Gensim Library**

#### Gensim is an open-source library for unsupervised topic modeling, document indexing, retrieval by similarity, and other natural language processing functionalities, using modern statistical machine learning.

Gensim overview: https://radimrehurek.com/gensim/intro.html#what-is-gensim

documentataion: https://radimrehurek.com/gensim/auto_examples/index.html

All gensim models are listed on this page: https://github.com/RaRe-Technologies/gensim-data

## **word2vec-google-news-300 Model**

based and trained on Google News data.
"""

import gensim.downloader as api
# This is a huge model (~1.6 gb) and it will take some time to load

wv = api.load('word2vec-google-news-300')
# in here we can sepcify which dataset or what kind of word embedding we need to download.
#

"""these simillarites are based on the context thay appear. not because of synonims or antonyms."""

wv.similarity(w1="great", w2="great")

wv.similarity(w1="great", w2="good")

wv.similarity(w1="great", w2="well")

wv.similarity(w1="profit", w2="gain")

wv.most_similar("good")

"""why bad appers as a most simillar word list for good. beacuse of the context,

**EX :- i was feeling good as it was a holiday...i was feeling bad as it was a monday**

* like that context the sorrounding is affects here. where it apperas matter.

* the TF-IDF & bag of words modles can't understand the semantic similarity between words like this better.
"""

wv.most_similar("profit")

wv.most_similar("dog")

"""#### **Doing arithmatic in Word2Vec**

* King - woman + man = Queen

* France - Paris + Berlin = Germany
"""

wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=5)

wv.most_similar(positive=['france', 'berlin'], negative=['paris'], topn=5)

wv.doesnt_match(["facebook", "cat", "google", "microsoft"])

wv.doesnt_match(["dog", "cat", "google", "mouse"])

wv.doesnt_match(["supra", "godzilla", "raptor", "ninja"])

"""## **Gensim: Glove**

based and trained on twitter data.

Stanford's page on GloVe: https://nlp.stanford.edu/projects/glove/
"""

glv = api.load("glove-twitter-25")

glv.most_similar("good")

glv.most_similar("supra")

glv.most_similar("godzilla")

glv.doesnt_match("breakfast cereal dinner lunch".split())

glv.doesnt_match("facebook cat google microsoft".split())

glv.doesnt_match("banana grapes orange human".split())