# -*- coding: utf-8 -*-
"""Text Representation in NLP (stop words).ipynb

Automatically generated by Colab.

## **Stop Words Tutorial**
"""

import spacy

from spacy.lang.en.stop_words import STOP_WORDS

len(STOP_WORDS)

STOP_WORDS

nlp = spacy.load("en_core_web_sm")

doc = nlp("We just opened our wings, the flying part is coming soon")

for token in doc:
    if token.is_stop: #method
        print(token)

#complete this
#def prerocess(text):
  #doc = nlp(text)

  #for token in doc:
    #if not token.is_stop:

def preprocess(text):
    doc = nlp(text)

    #using list comprehention
    no_stop_words = [token.text for token in doc if not token.is_stop and not token.is_punct]
    return (no_stop_words)

preprocess("We just opened our wings, the flying part is coming soon")

"""### array into list"""

def preprocess(text):
    doc = nlp(text)

    #using list comprehention
    no_stop_words = [token.text for token in doc if not token.is_stop and not token.is_punct]
    return " ".join(no_stop_words)

    #we don't want string we need string
    #to convert array into list we use join in python
    #it will take all the list elements and create aarray out of it

preprocess("We just opened our wings, the flying part is coming soon")

preprocess("The other is not other but your divine brother")

preprocess("Musk wants time to prepare for a trial over his")

"""**Remove stop words from pandas dataframe text column**

Dataset is downloaded from: https://www.kaggle.com/datasets/jbencina/department-of-justice-20092018-press-releases It contains press releases of different court cases from depart of justice (DOJ). The releases contain information such as outcomes of criminal cases, notable actions taken against felons, or other updates about the current administration.
"""

import pandas as pd

df = pd.read_json("/doj_press.json",lines=True)

df.shape

df.head()

"""### **Filter out those rows that do not have any topics associated with the case**"""

df.info

type(df.topics[0]) #for topics column

#filtering part (set the condition)

df = df[df["topics"].str.len()!=0]  #convert it to str and check the lenth
df.head()

#we can also use lamda function to check the lenth of the list

df.shape

df =df.head(100) #take only 1st 100 rows as df
df.shape

df["contents"]

df["contents"].iloc[4]

len(df["contents"].iloc[4]) #check the lenth then remove the stop words

#df["contents_new"] = df["contents"].apply(preprocess)     #check this also works

df["contents_new"] = df.contents.apply(preprocess) #apply earlier created preprocess function

df.head()

df

len(df["contents"].iloc[4]) #old length

len(df["contents_new"].iloc[4]) #new length after removing stop words

df["contents"].iloc[4][:300] #old

df["contents_new"].iloc[4][:300] #new

len(df.contents[4])

len(df.contents_new[4])

"""### Examples where removing stop words can create a problem

**(1) Sentiment detection: Not always but in some cases, based on your dataset it can change the sentiment of a sentence if you remove stop words**
"""

preprocess("this is a good movie")

preprocess("this is not a good movie")

"""**(2) Language translation: Say you want to translate following sentence from english to telugu. Before actual translation if you remove stop words and then translate, it will produce horrible result**"""

preprocess("how are you doing dhaval?")

"""**(3) Chat bot or any Q&A system**"""

preprocess("I don't find yoga mat on your website. Can you help?")